# -*- coding: utf-8 -*-
"""Submission_ML (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14KCQTPqOsEEi7pbQKJQqE2wP280nNfcU

Nama : ALEISYA ZAHARI SALAM

[LinkedIn](https://www.linkedin.com/in/aleisya-zahari-salam-5b8090222/)
"""

#import
import zipfile, os

"""# Download file"""

!gdown 1Qi8IWjXnvrRFhFSFkx5OKGdYkaPzG5ue

"""# Kriteria Submission

Berikut kriteria submission yang harus Anda penuhi:

- Dataset yang dipakai haruslah dataset berikut : rockpaperscissors, atau gunakan link ini pada wget command: https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip.


- Dataset harus dibagi menjadi train set dan validation set.
Ukuran validation set harus 40% dari total dataset (data training memiliki 1314 sampel, dan data validasi sebanyak 874 sampel).

- Harus mengimplementasikan augmentasi gambar.

- Menggunakan image data generator.

- Model harus menggunakan model sequential.

- Pelatihan model tidak melebihi waktu 30 menit.

- Program dikerjakan pada Google Colaboratory.
- Akurasi dari model minimal 85%.
- Dapat memprediksi gambar yang diunggah ke Colab seperti gambar di bawah.
202004302318257ec23b834046174a7d426680e488905e.png
-Manambahkan data diri (sesuai profil Dicoding) pada submission/project yang dikirimkan.

# Unzip Dataset
"""

!unzip '/content/rockpaperscissors.zip'

"""# Membuat direktori"""

base_dir = '/content/rockpaperscissors'

"""# Preprocessing Image"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Pembagian Data split train dan validation yaitu 60:40

datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range=0.2,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.4
)

train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    classes = ['paper', 'rock', 'scissors']
)

validation_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    classes=['paper', 'rock', 'scissors']
)

"""# Pembuatan Model"""

from tensorflow import keras

model = keras.Sequential([
    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    keras.layers.Conv2D(64, (3,3), activation='relu'),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Conv2D(128, (3,3), activation='relu'),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Flatten(),
    # keras.layers.Dropout(0.2),
    keras.layers.Dense(512, activation = 'relu'),
    keras.layers.Dense(3, activation='softmax')  # Urutan classes: paper, rock, scissors
])

model.summary()

"""# Model Train"""

from tensorflow.keras.callbacks import EarlyStopping

class myCallback(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')> 0.95):
      print("\nAkurasi telah mencapai 95%, hentikan training!")
      self.model.stop_training = True

callbacks = myCallback()

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_generator,
                    epochs=20,
                    steps_per_epoch = 15,
                    validation_data = validation_generator,
                    callbacks = [callbacks], verbose = 1)

"""# Evaluasi"""

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('accuracy plot')
plt.ylabel('value')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('loss plot')
plt.ylabel('value')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt

# Plot the results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()

"""# Testing"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
    path = fn
    img = image.load_img(path, target_size=(150, 150))
    imgplot = plt.imshow(img)
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x /= 255.0

    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)[0]

    print(fn)
    print("Raw Predictions:", classes)

    predicted_class_index = np.argmax(classes)

    if predicted_class_index == 0:
        print('Paper')
    elif predicted_class_index == 1:
        print('Rock')
    else:
        print('Scissors')